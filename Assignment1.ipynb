{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: POS tagging, Sequence labelling, RNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dKzlqJPq0I9E"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-09 15:40:38.874487: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-09 15:40:38.925404: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-09 15:40:38.926148: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-09 15:40:39.860633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import urllib\n",
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    classification_report,\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Embedding, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CFPsa10V0I9F"
      },
      "outputs": [],
      "source": [
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    # os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\" ### can make training slower\n",
        "\n",
        "\n",
        "set_reproducibility(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_5JrteW0I9G"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZKcsCMU0I9G"
      },
      "source": [
        "### Download the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ngly-2b_0I9I"
      },
      "outputs": [],
      "source": [
        "def download_url(download_path: Path, url: str):\n",
        "    urllib.request.urlretrieve(url, filename=download_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sbiv7Zr0I9I",
        "outputId": "ad38d8fe-a480-4867-d5d5-20c4b77f20ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already downloaded!\n",
            "Dataset already extracted!\n"
          ]
        }
      ],
      "source": [
        "dataset_url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
        "if not dataset_folder.exists():\n",
        "    dataset_folder.mkdir(parents=True)\n",
        "\n",
        "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
        "if not dataset_zip_path.exists():\n",
        "    print(\"Downloading dataset... \", end=\"\")\n",
        "    download_url(url=dataset_url, download_path=dataset_zip_path)\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded!\")\n",
        "dataset_path = dataset_folder.joinpath(dataset_name)\n",
        "\n",
        "if not dataset_path.exists():\n",
        "    print(\"Extracting dataset... (it may take a while...) \", end=\"\")\n",
        "    shutil.unpack_archive(dataset_zip_path, dataset_folder)\n",
        "    print(\"Extraction completed!\")\n",
        "else:\n",
        "    print(\"Dataset already extracted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05sbc2yW0I9I"
      },
      "source": [
        "#### Encode the corpus into a pandas DataFrame object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hG4eepnY0I9J"
      },
      "outputs": [],
      "source": [
        "folder = dataset_folder.joinpath(dataset_name)\n",
        "\n",
        "\n",
        "dataframe_rows = []\n",
        "for file_path in sorted(folder.glob(\"*.dp\")):\n",
        "    with file_path.open(mode=\"r\", encoding=\"utf-8\") as text_file:\n",
        "        text = text_file.read()\n",
        "        ### Split sentences (\\n\\n is used for most NLP datasets to split sentences)\n",
        "        sentences = text.split(\"\\n\\n\")\n",
        "\n",
        "        ### Observing each sentence\n",
        "        for s in sentences:\n",
        "            sentence = []\n",
        "            tags = []\n",
        "            ### Taking every line\n",
        "            for line in s.split(\"\\n\"):\n",
        "                columns = line.split(\"\\t\")\n",
        "                ### If every line have word, tag, value\n",
        "                if len(columns) > 2:\n",
        "                    ### Put words and tags into lists\n",
        "                    sentence.append(columns[0])\n",
        "                    tags.append(columns[1])\n",
        "\n",
        "            file_id = int(file_path.stem.split(\"_\")[1])\n",
        "            dataframe_row = {\"file_id\": file_id, \"sentence\": sentence, \"tag\": tags}\n",
        "            dataframe_rows.append(dataframe_row)\n",
        "\n",
        "df = pd.DataFrame(dataframe_rows)\n",
        "\n",
        "FILE_ID, SENTENCE, TAGS = df.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X0EppNXK0I9K",
        "outputId": "e782ab64-ef89-4f01-8cda-d07c9fa52986"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   file_id                                           sentence  \\\n",
              "0        1  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1        1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2        2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3        3  [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4        3  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                                 tag  \n",
              "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  \n",
              "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  \n",
              "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  \n",
              "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  \n",
              "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2cFd_wR0I9K"
      },
      "source": [
        "#### Splitting Data Train-Test-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J0spDKZN0I9L"
      },
      "outputs": [],
      "source": [
        "### File indices for train/validation/test\n",
        "train_ids = np.arange(1, 101)\n",
        "val_ids = np.arange(101, 151)\n",
        "test_ids = np.arange(151, 200)\n",
        "\n",
        "df_train = df[df[FILE_ID].isin(train_ids)]\n",
        "df_val = df[df[FILE_ID].isin(val_ids)]\n",
        "df_test = df[df[FILE_ID].isin(test_ids)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J38RHhnT0I9L"
      },
      "source": [
        "# [Task 2 - 0.5 points] Text encoding\n",
        "\n",
        "To train a neural POS tagger, you first need to encode text into numerical format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm45krA-0I9L"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-0uWNkvL0I9L"
      },
      "outputs": [],
      "source": [
        "### Download Glove\n",
        "\n",
        "embedding_dim = 100\n",
        "glove_file = f\"glove.6B.{embedding_dim}d.txt\"\n",
        "glove_zip = \"glove.6B.zip\"\n",
        "glove_path = Path.cwd().joinpath(glove_file)\n",
        "if not glove_path.exists():\n",
        "    urllib.request.urlretrieve(\n",
        "        \"http://nlp.stanford.edu/data/glove.6B.zip\", Path.cwd().joinpath(glove_zip)\n",
        "    )\n",
        "    with zipfile.ZipFile(glove_zip, \"r\") as zip_ref:\n",
        "        zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbJxUUSy0I9L",
        "outputId": "bb53bb52-c174-48bf-878c-61b18a35cb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "with open(glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LL-AIxiA0I9L"
      },
      "outputs": [],
      "source": [
        "# max_sequence_length = int(np.quantile([len(seq) for seq in df_train[\"sentence\"]], 0.99))\n",
        "max_sequence_length = max([len(seq) for seq in df_train[SENTENCE]])\n",
        "\n",
        "# TODO remove\n",
        "hparams = {\n",
        "    \"batch_size\": 128,\n",
        "    \"embedding_dim\": 100,\n",
        "    \"embedding_trainable\": False,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"max_sequence_length\": max_sequence_length,\n",
        "    \"vocab_size\": 7405,\n",
        "    \"tag_size\": 46,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z7RKxZ0G0I9M"
      },
      "outputs": [],
      "source": [
        "### Preprocessing: lowercase\n",
        "def make_lower(df):\n",
        "    df[SENTENCE].apply(lambda l: [i.lower() for i in l])\n",
        "\n",
        "\n",
        "make_lower(df_train)\n",
        "make_lower(df_val)\n",
        "# TODO va bene fare lowercase sul test set? vediamo se va senza\n",
        "# make_lower(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g9-1Yp4p0I9M"
      },
      "outputs": [],
      "source": [
        "### Use Keras Tokenizer to create Vocabulary\n",
        "\n",
        "# TODO ci hanno consigliato codice deprecato (tokenizer) io vorrei usare TextVectorization ma fa schifo\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(df_train[\"sentence\"])\n",
        "\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(df_train[\"tag\"])\n",
        "\n",
        "\n",
        "### Turn text into into padded sequences.\n",
        "def prep_text(texts, tokenizer, max_sequence_length):\n",
        "    text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "    return sequence.pad_sequences(\n",
        "        text_sequences, maxlen=max_sequence_length, padding=\"post\"\n",
        "    )\n",
        "\n",
        "\n",
        "text_train = prep_text(df_train[\"sentence\"], tokenizer, max_sequence_length)\n",
        "text_test = prep_text(df_test[\"sentence\"], tokenizer, max_sequence_length)\n",
        "text_val = prep_text(df_val[\"sentence\"], tokenizer, max_sequence_length)\n",
        "\n",
        "tag_train = prep_text(df_train[\"tag\"], tag_tokenizer, max_sequence_length)\n",
        "tag_test = prep_text(df_test[\"tag\"], tag_tokenizer, max_sequence_length)\n",
        "tag_val = prep_text(df_val[\"tag\"], tag_tokenizer, max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNUsZd2M0I9N",
        "outputId": "4823bf3b-8d6e-4499-e4ee-66a4a70ce743"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2,  2,  7, 11,  5,  6,  7, 20, 12,  4,  1,  3,  4,  6,  1,  2, 11,\n",
              "        8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tag_train.shape\n",
        "tag_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5jivo8rj0I9N"
      },
      "outputs": [],
      "source": [
        "### Encode the tags in 1hot encoding\n",
        "\n",
        "num_classes = len(tag_tokenizer.word_index) + 1\n",
        "tag_categorical_train = to_categorical(tag_train, num_classes)\n",
        "tag_categorical_test = to_categorical(tag_test, num_classes)\n",
        "tag_categorical_val = to_categorical(tag_val, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8emt0iR0I9N",
        "outputId": "70c427f8-1da6-4ed4-e054-06c3b54d8296"
      },
      "outputs": [],
      "source": [
        "all_classes = list(tag_tokenizer.word_index.keys())\n",
        "all_tokens = list(tag_tokenizer.word_index.values())\n",
        "punct_classes = [\",\", \".\", \":\", \"``\", \"''\", \"$\", \"#\", \"sym\", \"-rrb-\", \"-lrb-\"]\n",
        "punct_tokens = [tag_tokenizer.word_index[p] for p in punct_classes]\n",
        "allowed_classes = [\n",
        "    word for word in tag_tokenizer.index_word.values() if word not in punct_classes\n",
        "]\n",
        "allowed_tokens = [token for token in all_tokens if token not in punct_tokens]\n",
        "\n",
        "print(f\"Tags: {all_classes}\")\n",
        "print(f\"All tag-tokens: {all_tokens}\\n\")\n",
        "print(f\"Punctuations: {punct_classes}\")\n",
        "print(f\"Tokenized punctuations {punct_tokens}\\n\")\n",
        "print(f\"Tags without punctuation: {allowed_classes}\")\n",
        "print(f\"Tokens will be used in evaluations: {allowed_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xDsxfWt0I9N",
        "outputId": "569a926f-74c7-4b08-d266-0f6d36f084c4"
      },
      "outputs": [],
      "source": [
        "### Create the embedding matrix\n",
        "embeddings_index = {}\n",
        "with open(glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")\n",
        "\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "num_words_in_embedding = 0\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        num_words_in_embedding += 1\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTUDtH800I9O",
        "outputId": "6704a562-0082-4411-8bbe-5eefaee0ebc7"
      },
      "outputs": [],
      "source": [
        "### Inspect tokens' embedding vectors\n",
        "idx_token = 2\n",
        "print(\n",
        "    f\"Token: {list(tokenizer.word_index.keys())[idx_token]} \\nVector: {embedding_matrix[idx_token]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wElwxfb0I9O"
      },
      "outputs": [],
      "source": [
        "# TODO fare un po' di inspection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7wJf8ew0I9P"
      },
      "source": [
        "# [Task 3 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your neural POS tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xVpNdEZ0I9P"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
        "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
        "\n",
        "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
        "\n",
        "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfs_L1hE0I9P"
      },
      "outputs": [],
      "source": [
        "def get_model(lstm_units=64, add_lstm=False, add_dense=False):\n",
        "    number_of_words = len(tokenizer.word_index.keys())\n",
        "    number_of_tags = len(tag_tokenizer.word_index.keys())\n",
        "\n",
        "    input = Input(shape=(max_sequence_length,))\n",
        "\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim=number_of_words + 1,\n",
        "        output_dim=embedding_dim,\n",
        "        input_length=max_sequence_length,\n",
        "        weights=[embedding_matrix],\n",
        "        trainable=False,\n",
        "    )(input)\n",
        "    bi_lstm = Bidirectional(LSTM(lstm_units, return_sequences=True))(embedding_layer)\n",
        "    bi_lstm2 = (\n",
        "        Bidirectional(LSTM(lstm_units, return_sequences=True))(bi_lstm)\n",
        "        if add_lstm\n",
        "        else bi_lstm\n",
        "    )\n",
        "    dense2 = (\n",
        "        TimeDistributed(Dense(number_of_tags + 1, activation=\"relu\"))(bi_lstm2)\n",
        "        if add_dense\n",
        "        else bi_lstm\n",
        "    )\n",
        "    dense_output = TimeDistributed(Dense(number_of_tags + 1, activation=\"softmax\"))(\n",
        "        dense2\n",
        "    )\n",
        "    model = Model(input, dense_output)\n",
        "\n",
        "    ### No logits: we have 1 hot encoding as labels\n",
        "    model.compile(\n",
        "        loss=CategoricalCrossentropy(from_logits=False),\n",
        "        optimizer=Adam(5e-3),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    # model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VufgwYQ10I9P"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        "    min_delta=0.001,\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    factor=0.1,\n",
        "    patience=7,\n",
        "    cooldown=1,\n",
        "    min_lr=1e-5,\n",
        "    min_delta=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR1ilMZ-0I9P"
      },
      "source": [
        "# [Task 4 - 1.0 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzd_nWCQ0I9Q"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
        "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n",
        "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwjdeYRs0I9Q"
      },
      "source": [
        "**Note**: What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe are **not** considered as OOV\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvvX1aui0I9Q"
      },
      "outputs": [],
      "source": [
        "def metric(model, text, tag_categorical, labels=None):\n",
        "    # TODO what is a static embedding?\n",
        "\n",
        "    # TODO controllare che questo vada bene: fare la prova accumulando manualmente TP FP TN FN\n",
        "\n",
        "    y_pred = model.predict([text]).argmax(-1).flatten()\n",
        "    y_test_flatten = tag_categorical.argmax(-1).flatten()\n",
        "    score = f1_score(\n",
        "        y_test_flatten,\n",
        "        y_pred,\n",
        "        labels=labels,  # allowed tokens\n",
        "        average=\"macro\",\n",
        "        zero_division=0,\n",
        "    )\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKqM46B0I9Q"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPx2pXEb0I9Q"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvbi3kvP0I9Q"
      },
      "outputs": [],
      "source": [
        "def experiment(seed, model1=False, model2=False):\n",
        "    set_reproducibility(seed)\n",
        "\n",
        "    model = get_model(add_lstm=model1, add_dense=model2)\n",
        "\n",
        "    ### train model on the train set\n",
        "    history = model.fit(\n",
        "        text_train,\n",
        "        tag_categorical_train,\n",
        "        batch_size=128,\n",
        "        epochs=50,\n",
        "        validation_data=(text_val, tag_categorical_val),\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "    )\n",
        "\n",
        "    ### compute metrics\n",
        "    score = metric(model, text_val, tag_categorical_val)\n",
        "\n",
        "    return score, history, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p94lgBYl0I9R"
      },
      "outputs": [],
      "source": [
        "seeds = [333, 666, 999]\n",
        "seeds = [333]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfqpnOhn0I9R",
        "outputId": "21173502-8b59-4864-f2f8-32e69304897e"
      },
      "outputs": [],
      "source": [
        "### baseline\n",
        "baseline_results = [experiment(s) for s in seeds]\n",
        "baseline_scores = [r[0] for r in baseline_results]\n",
        "baseline_histories = [r[1] for r in baseline_results]\n",
        "baseline_models = [r[2] for r in baseline_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "LZXj5av10I9R",
        "outputId": "b913cb5f-5a67-468f-9e74-ad1b0d919370"
      },
      "outputs": [],
      "source": [
        "[print(h) for h in baseline_scores]\n",
        "[plt.plot(h.history[\"loss\"]) for h in baseline_histories]\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46QYti0H0I9R",
        "outputId": "fbb99bf3-5f94-4b66-ad1f-3ce3cf199193"
      },
      "outputs": [],
      "source": [
        "### model1\n",
        "model1_results = [experiment(s, model1=True) for s in seeds]\n",
        "model1_scores = [r[0] for r in model1_results]\n",
        "model1_histories = [r[1] for r in model1_results]\n",
        "model1_models = [r[2] for r in model1_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "xbWGnixU0I9R",
        "outputId": "388e4930-c49f-4ca3-c829-7763ebf736cc"
      },
      "outputs": [],
      "source": [
        "[print(h) for h in model1_scores]\n",
        "[plt.plot(h.history[\"loss\"]) for h in model1_histories]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snfr3NNo0I9S",
        "outputId": "0b4f4a7a-4577-4380-f127-0ba3ebdd8ed0"
      },
      "outputs": [],
      "source": [
        "### model2\n",
        "model2_results = [experiment(s, model2=True) for s in seeds]\n",
        "model2_scores = [r[0] for r in model2_results]\n",
        "model2_histories = [r[1] for r in model2_results]\n",
        "model2_models = [r[2] for r in model2_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "fn6Mx_Xt0I9S",
        "outputId": "62bda1ac-9920-4a24-969b-06f295a91c60"
      },
      "outputs": [],
      "source": [
        "[print(h) for h in model2_scores]\n",
        "[plt.plot(h.history[\"loss\"]) for h in model2_histories]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### compute metrics on validation set\n",
        "\n",
        "baseline_val_metrics = [\n",
        "    metric(m, text_val, tag_categorical_val, labels=allowed_tokens)\n",
        "    for m in baseline_models\n",
        "]\n",
        "model1_val_metrics = [\n",
        "    metric(m, text_val, tag_categorical_val, labels=allowed_tokens)\n",
        "    for m in model1_models\n",
        "]\n",
        "model2_val_metrics = [\n",
        "    metric(m, text_val, tag_categorical_val, labels=allowed_tokens)\n",
        "    for m in model2_models\n",
        "]\n",
        "\n",
        "# facendo la media: non credo abbia senso: possiamo fare la media degli score ma non la media dei modelli (dei parametri)\n",
        "# e adesso dovrei prendere 3 modelli e fare la media (come?)\n",
        "\n",
        "\n",
        "# senza fare la media\n",
        "# ogni modello ha 3 chances di fare bene, poi prendiamo il cadidato migliore\n",
        "\n",
        "# se dopo lo dovessimo allenare di nuovo (meglio, di più, su più dati) allora\n",
        "# avrebbe senso prendere L'ARCHITETTURA che ha dato la media migliore\n",
        "# una specie di genetic programming\n",
        "\n",
        "# ci deve essere un modo più efficiente (meno memoria) per fare questa cosa\n",
        "# non voglio concatenare le liste\n",
        "### pick best performing model\n",
        "names = [\n",
        "    f\"{model}_{seed}\" for model in [\"baseline\", \"model1\", \"model2\"] for seed in seeds\n",
        "]\n",
        "d = {}\n",
        "# metti in parallelo le liste\n",
        "for model_list, score_list, name_list in zip(\n",
        "    [baseline_models, model1_models, model2_models],\n",
        "    [baseline_val_metrics, model1_val_metrics, model2_val_metrics],\n",
        "    [\n",
        "        [f\"baseline_{s}\" for s in seeds],\n",
        "        [f\"model1_{s}\" for s in seeds],\n",
        "        [f\"model2_{s}\" for s in seeds],\n",
        "    ],\n",
        "):\n",
        "    # itera sugli elementi di ogni lista\n",
        "    for m, s, n in zip(model_list, score_list, name_list):\n",
        "        d.update({s: (m, n)})\n",
        "\n",
        "val_score = max(d)\n",
        "best_model, best_model_name = d[val_score]\n",
        "\n",
        "print(f\"best model: {best_model_name}\")\n",
        "\n",
        "# report: commento sui risultati: il training è un po' rumoroso (si può migliorare),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5WfKXd90I9S"
      },
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to evaluate your best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He8u4f_-0I9S"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Compare the errors made on the validation and test sets.\n",
        "* Aggregate model errors into categories (if possible)\n",
        "* Comment the about errors and propose possible solutions on how to address them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvYNzPw40I9S"
      },
      "outputs": [],
      "source": [
        "### compare errors made on validation and test set\n",
        "test_score = metric(best_model, text_test, tag_categorical_test, labels=allowed_tokens)\n",
        "print(test_score)\n",
        "\n",
        "val_score_per_cat = [\n",
        "    metric(best_model, text_val, tag_categorical_val, labels=[t])\n",
        "    for t in allowed_tokens\n",
        "]\n",
        "test_score_per_cat = [\n",
        "    metric(best_model, text_test, tag_categorical_test, labels=[t])\n",
        "    for t in allowed_tokens\n",
        "]\n",
        "\n",
        "### aggregate model erors into categories\n",
        "\n",
        "# spero che categories siano quelle della classificazione e non \"categorie di errori\" tipo FP FN\n",
        "print(\"TAG\\tval\\ttest\")\n",
        "for c, v, t in zip(allowed_classes, val_score_per_cat, test_score_per_cat):\n",
        "    print(f\"{c}\\t{v}\\t{t}\")\n",
        "\n",
        "# propose solutions:  qualche categoria manca qui e là"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Predict on validation and test set\n",
        "### argmax transforms from categorical to numbers\n",
        "\n",
        "tag_pred_val = best_model.predict([text_val]).argmax(-1)\n",
        "tag_pred_test = best_model.predict([text_test]).argmax(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_distribution(data):\n",
        "    unique, counts = np.unique(data, return_counts=True)\n",
        "    counts = dict(zip(unique, counts))\n",
        "    # TODO: li sorto sulla label per far vedere le differenze di frequenza\n",
        "    counts = dict(sorted(counts.items(), key=lambda item: item[0], reverse=False))\n",
        "\n",
        "    ### If the tag_token is not allowed then delete it.\n",
        "    for key in unique:\n",
        "        if key not in allowed_tokens:\n",
        "            del counts[key]\n",
        "    labels = [tag_tokenizer.index_word[index] for index in counts.keys()]\n",
        "    result = dict(zip(labels, counts.values()))\n",
        "    return result\n",
        "\n",
        "\n",
        "def plot_data_distribution(data, name):\n",
        "    counts = get_data_distribution(data)\n",
        "    keys = list(counts.keys())\n",
        "    values = list(counts.values())\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    plt.barh(keys, values, color=\"#902e59\")\n",
        "    plt.title(f\"Class Distribution of {name}\")\n",
        "    plt.ylabel(\"Tags\")\n",
        "    plt.xlabel(\"Count\")\n",
        "    plt.tick_params(labelsize=8)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_data_distribution(tag_train, name=\"Train Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_data_distribution(tag_val, name=\"Validation Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_data_distribution(tag_test, name=\"Test Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_cf_report(tag_pred, tag):\n",
        "    cf_report_val = pd.DataFrame(\n",
        "        classification_report(\n",
        "            tag_pred.flatten(),\n",
        "            tag.flatten(),\n",
        "            labels=all_tokens,\n",
        "            target_names=all_classes,\n",
        "            zero_division=0,\n",
        "            output_dict=True,\n",
        "        )\n",
        "    ).transpose()\n",
        "    cf_report_val.reset_index(inplace=True)\n",
        "    cf_report_val.columns = [\"tags\", \"precision\", \"recall\", \"f1-score\", \"support\"]\n",
        "\n",
        "    print(\n",
        "        \"F1 score calculated on validation set:\",\n",
        "        f1_score(\n",
        "            tag_pred.flatten(),\n",
        "            tag.flatten(),\n",
        "            labels=all_tokens,\n",
        "            zero_division=0,\n",
        "            average=\"macro\",\n",
        "        ),\n",
        "        \"\\n\",\n",
        "    )\n",
        "    return cf_report_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Display classification report for Validation Set\n",
        "cf_report_val = get_cf_report(tag_pred_val, tag_val)\n",
        "display(cf_report_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Display classification report for Test Set\n",
        "cf_report_test = get_cf_report(tag_pred_test, tag_test)\n",
        "display(cf_report_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc02ygSz0I9T"
      },
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDVRC6he0I9T"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ZISkw50I9T"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIo631ni0I9T"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltyeaCUr0I9T"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UQ-EFWq0I9T"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruAgGPb_0I9U"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YqTa-dG0I9U"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPwxnrta0I9U"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r68nIGLH0I9U"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVmpO6gX0I9V"
      },
      "source": [
        "### Punctuation\n",
        "\n",
        "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
        "\n",
        "You should **ignore** it during metrics computation.\n",
        "\n",
        "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It3HUc060I9V"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
